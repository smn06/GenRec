{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd34c22-8bdd-407f-aa83-a8fb7ae56633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the Generator and Discriminator architectures\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Parameters\n",
    "input_dim = 100\n",
    "output_dim = 10  # Assuming user profiles have 10 features\n",
    "num_epochs = 5000\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '../data/processed/synthetic_user_profiles.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.values\n",
    "\n",
    "# Normalize data\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "# Create DataLoader\n",
    "tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "dataset = TensorDataset(tensor_data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the models\n",
    "generator = Generator(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "discriminator = Discriminator(input_dim=output_dim).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "\n",
    "# Training loop\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "for epoch in range(num_epochs):\n",
    "    for real_data in dataloader:\n",
    "        real_data = real_data[0].to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "        # Create labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "        outputs = discriminator(real_data)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        \n",
    "        noise = torch.randn(batch_size, input_dim).to(device)\n",
    "        fake_data = generator(noise)\n",
    "        outputs = discriminator(fake_data.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        noise = torch.randn(batch_size, input_dim).to(device)\n",
    "        fake_data = generator(noise)\n",
    "        outputs = discriminator(fake_data)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "    losses_g.append(g_loss.item())\n",
    "    losses_d.append(d_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]  Loss D: {d_loss.item()}, Loss G: {g_loss.item()}\")\n",
    "\n",
    "# Save the trained models\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "torch.save(generator.state_dict(), '../models/generator.pth')\n",
    "torch.save(discriminator.state_dict(), '../models/discriminator.pth')\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses_g, label='Generator Loss')\n",
    "plt.plot(losses_d, label='Discriminator Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
